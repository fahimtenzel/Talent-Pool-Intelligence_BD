{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "023f142a-1694-40a5-abc6-398349ed2469",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bronze Layer: Data Ingestion and Raw Storage (The Source of Truth)\n",
    "\n",
    "The **Bronze Layer** is the foundational layer of the Medallion Lakehouse Architecture. Its purpose is simple: to ingest the raw source data (our individual resume text files) with minimal transformation and store it reliably as a Delta Lake table.\n",
    "\n",
    "The data here is kept in its most original format. If we ever need to re-process the data from scratch due to new cleansing requirements, we always return to the Bronze Layer. The output of this layer is the `bronze_resumes` Delta table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6607da30-a2d0-4114-ad48-64ba313c7d99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Ingestion: Reading Files from the Volume\n",
    "\n",
    "This section performs the initial data load. We use the PySpark `text` format to read all individual resume files (`*.txt`) from the secure Volume location. PySpark automatically assigns a unique ID (`monotonically_increasing_id`) and puts the entire resume content into a single column (`value`), which we alias as `Resume_Text`.\n",
    "\n",
    "Crucially, the data is saved as a **Delta Lake** table. Delta Lake ensures data reliability, transaction logging, and performance—core principles of the modern Lakehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b857602-6f26-4a05-a828-2357283dfc48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read all text files from: /Volumes/workspace/default/raw_resumes/*.txt\n\n✅ Successfully loaded 541 resumes.\n\n\uD83D\uDCBE Bronze table 'bronze_resumes' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Ingest Text Data (Bronze Layer) - Reverting to Volume Path\n",
    "\n",
    "# Import PySpark functions and types\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import re\n",
    "\n",
    "# 1. Configuration - Use the correct Volume path (assuming files are still there)\n",
    "volume_dir_path = \"/Volumes/workspace/default/raw_resumes/*.txt\" \n",
    "\n",
    "print(f\"Attempting to read all text files from: {volume_dir_path}\")\n",
    "\n",
    "# 2. Read the Text files into a PySpark DataFrame\n",
    "try:\n",
    "  raw_df = (\n",
    "    spark.read.format(\"text\")\n",
    "    .load(volume_dir_path)\n",
    "  )\n",
    "    \n",
    "  # Assign a unique ID and alias the text column\n",
    "  bronze_df = raw_df.select(\n",
    "      F.monotonically_increasing_id().alias(\"Resume_ID\"),\n",
    "      F.col(\"value\").alias(\"Resume_Text\") \n",
    "  )\n",
    "\n",
    "  print(f\"\\n✅ Successfully loaded {bronze_df.count()} resumes.\")\n",
    "  \n",
    "  # 3. Save the data to the Bronze Delta Table\n",
    "  bronze_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze_resumes\")\n",
    "  print(\"\\n\uD83D\uDCBE Bronze table 'bronze_resumes' created successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "  print(f\"\\n❌ Error loading data. Please ensure your compute is running and the path is correct. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze_Layer.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}